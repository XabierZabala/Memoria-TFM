%----------------------------------------------------%
%          ENTORNO DE PRUEBAS: CONSTRUCCION          %
%----------------------------------------------------%

\pagestyle{fancy}

\chapter{Entorno de pruebas: Construcción}
\label{entorno_pruebas}

En las próximas líneas se detallan las directrices seguidas a la hora de confeccionar los entornos de prueba posteriormente utilizados para cuantificar el rendimientos ofrecido por las tecnologías analizadas.\\

Para ello, se empezará por especificar las características físicas y la confección de los dispositivos utilizados para erigir dichos entornos:\\

\section{Características de las máquinas físicas}

\textit{Ordenador portátil}: Terminal encargado de lanzar diversas peticiones contra el servidor y recolectar los resultados computados por este cuantificando el tiempo transcurrido entre ambos eventos.\\ 

\begin{itemize}
	\item Procesador: Intel(R) Core(TM) i-5 4200M CPU @ 2.50 GHz
	\item Memoria RAM: 8 GB
	\item Disco Duro: Western Digital WD5000LPCX-24C6HTO SSD 500GB
	\item Sistema Operativo: Windows 10
	\item Adaptador Red: Qualcomm Atheros AR8172/8176/8178 PCI-E Fast Ethernet Controller (NDIS 6.30)
\end{itemize}

\textit{Ordenador de sobremesa}: Terminal que adquiere el rol de servidor dentro del entramado. Se encarga del tratamiento de los datos mediante el uso de las tecnología que se analizan en el presente proyecto.\\

\begin{itemize}
	\item Procesador: AMD FX(tm)-8350 Eight-Core Processor 4.00GHz
	\item Memoria RAM: 32 GB
	\item Disco Duro: Western Digital WD5000AAKX-22ERMA0 SSD 500GB
	\item Sistema Operativo: Windows 10
	\item Adaptador Red: Killer e2200 Gigabit Ethernet Controller (NDIS 6.30)
\end{itemize}

Ambas máquinas se encuentran enlazadas a un \textit{switch} tp-link-tl-sf1008d mediante sendos conectores Fast Ethernet, permitiendo intercambiar datos a una velocidad de 100 Mb/s.

El switch,  a su vez, está conectado a un \textit{router} que le proporciona acceso al exterior de la red privada, el cual sólo será utilizado para descargar contenido relativo al preparativo de las pruebas.\\ 

\section{Confección de las máquinas virtuales}

Las máquinas virtuales juegan un papel vital en el desarrollo de las pruebas. Gracias a ellas, es posible aislar completamente ambos entornos dentro del ordenador de sobremesa y además, permiten la creación de un clúster sin necesidad de adquirir más dispositivos.\\
 
Con el objetivo de no realizar las mismas configuraciones básicas reiteradamente, se ha decidido crear una máquina virtual básica y una vez configurada, clonarla tantas veces como instancias hagan falta para llevar a cabo las pruebas. Al considerar esta configuración un procedimiento trivial y carente de especial interés en el desarrollo del presente proyecto, los entresijos han sido omitidos, describiendo solamente la motivación de cada paso.\\

\begin{enumerate}
	
	\item \textit{Crear la máquina virtual básica}:\\\\Instancia creada mediante VirtualBox utilizando una imagen de Ubuntu Server 16.04 LTS. Se le ha asignado una memoria física de 75 GB y mantenido tanto el número de procesadores como la memoria RAM que se le asigna por defecto, ya que estas dos últimas características son modificables posteriormente.\\ 
	
	\item \textit{Asignar una IP estática}:\\\\Todos los clones realizados sobre la instancia básica operarán como servidores, por lo que no es de recibo que su IP pueda variar cada vez que el servicio de red o la máquina misma se reinicien. Para evitar cualquier inconveniente de este estilo, es totalmente necesario configurar una interfaz de red con una IP estática por la cual se podrá acceder a la máquina.\\
	
	\item \textit{Cambiar el adaptador de red a modo puente}:\\\\Al crear una máquina virtual con VirtualBox, el adaptador de red predefinido es el NAT. Ello implica que dicha máquina se encontrará aislada en una red lógica y solo podrá acceder a otros dispositivos pasando por la máquina física y haciendo uso de su IP.\\
	Modificando el adaptador de red al modo puente, se consigue extender la red privada hasta el nodo virtual eliminando así toda dependencia con la máquina física en cuanto a comunicaciones se refiere, posibilitando que acceda al resto de las máquinas que residen en la misma red privada.\\
	
	\item \textit{Instalar Java 8}:\\\\El software que se va a arrancar en las instancias clonadas se ejecuta sobre la Máquina Virtual de Java(JVM), por lo que es necesario tener una versión de Java instalada en la máquina virtual base.\\
	
	\begin{lstlisting}[language=bash]
	sudo add-apt-repository ppa:webupd8team/java
	sudo apt-get update
	sudo apt-get install oracle-java8-installer
	\end{lstlisting}
	
	\item \textit{Instalar SSH Server}:\\\\Aunque no se considere estrictamente necesario llevar a cabo este último paso, es de gran ayuda poder acceder a las máquinas virtuales mediante SSH y transferir archivos utilizando SFTP.\\
	
	\begin{lstlisting}[language=bash]
	sudo apt install openssh-server
	\end{lstlisting}

\end{enumerate}

Una vez terminado de confeccionar la máquina virtual básica, es aconsejable calcular ciertas métricas como la latencia y el número de saltos que se dan por la red hasta llegar al nodo destino, ya que pueden aflorar anomalías existentes en la configuración.\\ 

Ejecutando el comando \textit{tracert} en el ordenador portátil y especificando como parámetro la IP correspondiente a la máquina virtual recién confeccionada, se han obtenido latencias inferiores a 1ms y un único salto entre ambos nodos, lo cual implica que los paquetes enviados llegan a su destino casi al instante y sin salir de la red privada.\\

\section{Entorno centralizado}

emular el entorno que actualmente datik posee y el rendimiento que da

\begin{enumerate}
	\item Nested item 1
	\item Nested item 2
\end{enumerate}


\section{Entorno distribuido}

\begin{enumerate}
	\item Nested item 1
	\item Nested item 2
\end{enumerate}

A continuación se detallan los pasos más relevantes llevados a cabo para construir y configurar el entorno distribuido o clusterizado. Instalar las máquinas virtuales que operan cual nodos y dotarlos de un sistema operativo se ha considerado un procedimiento trivial y carente de interés por lo cual estos pasos han sido omitidos.\\ 



///Configuración de los fichero etc/hosts

Para finalizar, es indispensable que cada máquinas conozca a las otras que componen el cluster para que estos actúen de forma  cooperativa. Dicha información les será transmitida mediante el fichero /etc/hosts.

En el siguiente recuadro se puede apreciar la apariencia que han de tener los ficheros /etc/hosts de todas las máquinas del cluster:

192.168.1.201 master
192.168.1.202 slave1
192.168.1.203 slave2

El motivo por el cual unos pasos atrás se ha asignado un hostname a cada máquina virtual sido para, mediante este fichero, relacionar cada host con su respectiva IP. A priori, no parece que sea estrictamente necesario realizar esta configuración, ya que una dirección IP es elemento suficiente para identificar un terminal en la red, pero a la larga ofrece diversas ventajas. Por un lado  ventajas operativas: un nombre es más fácil de relacionar a un nodo gracias a la semántica inherente a el, algo que no pasa con una IP, que a la postre, cambia si el nodo es trasladado de una red a otra. Por otro lado, las ventajas funcionales como las que se van a poder observar en el siguiente apartado; por ejemplo, que algunas variables de Apache Cassandra, en caso de no ser configurados, recurren a este fichero para conocer la IP de una máquina. 

\subsection{Configuración de Apache Cassandra}

Cassandra puede ser instalada mediante paquetes deb o rpm pero en este proyecto no se ha optado por ninguna de esa vía. Al haber elegido la instalación manual, será necesario crear los siguientes directorios en cada uno de los nodos para que el archivo de configuración cassandra.yaml pueda guardar y acceder a la información generada durante la ejecución:


%\begin{itemize}
%	\item /var/lib/cassandra/data
%	\item /var/lib/cassandra/commitlog
%	\item /var/lib/cassandra/saved_caches
%	\item /var/log/cassandra
%\end{itemize}


A su vez, para asegurar un correcto funcionamiento será vital que los directorios recién creados posean todos los permisos existentes. 

Tal y como se ha mencionado anteriormente, la configuración de Apache Cassandra se encuentra descrita en el fichero cassandra.yaml. Los valores que poseen ciertos atributos de este fichero han de ser reasignados en cada uno de los nodos para que Cassandra opere correctamente. Antes de mostrar la tabla XXX que agrupa dichos valores en cada nodo, se procederá a definirlos con la intención de entender la importancia que tienen en Cassandra.

%cluster_name

El nombre del cluster; usado para que las máquinas de un cluster lógico no se mezclen con otro. Todos los nodos del cluster deben de tener el mismo valor.

%initial_token

Se utiliza cuando el nodo tiene un rango contiguo en el anillo. Existen herramientas que especificando el número de nodos que componen el cluster calculan el valor del token para cada uno de estos.

%seed_provider

Una lista de direcciones IP delimitados por coma que se utilizan como punto de contacto para cuando un nodo se une al cluster. Cassandra también utiliza esta lista para aprender la topología del anillo.

%listen_address

La dirección IP que utilizan otros nodos para conectarse a una máquina especifica. Si no se indica nada, el nombre de la máquina tiene que conducir a su IP utilizando el fichero etc/hostname.

%rpc_address

La dirección IP de escucha para conexiones de cliente. El valor por defecto es localhost y sus valores posibles son:

\begin{itemize}
	\item 0.0.0.0: Escucha en todas la interfaces configuradas
	\item Dirección IP
	\item Nombre de máquina
	\item Sin especificar: el nombre de la máquina tiene que conducir a su IP utilizando el fichero etc/hostname
\end{itemize}
	
%endpoint_snitch

Establece el modo en el que Cassandra localiza nodos y envía peticiones de enrutamiento. Los más utilizados son los siguientes y a la hora de configurar los nodos, todos han de tener un mismo valor:

\begin{itemize}
	\item SimpleSnitch: Se utiliza solo para la implementación de centro de datos únicos.
	\item RackInferredSnitch: Determina la ubicación de los nodos por rack o por data center.
\end{itemize}
	 
Dichos atributos han sido configurados de la siguiente manera en el fichero cassandra.yaml de cada nodo del cluster: 

%BigData_Master	BigData_Slave1	BigData_Slave2
%cluster_name	BigDataCluster	BigDataCluster	BigDataCluster
%initial_token	0	3074457345618258602	6148914691236517205
%seed_provider	192.168.1.201	192.168.1.201	192.168.1.201
%listen_address	192.168.1.201	192.168.1.202	192.168.1.203
%rpc_address	0.0.0.0	0.0.0.0	0.0.0.0
%endpoint_snitch	RackInferringSnitch	RackInferringSnitch	RackInferringSnitch
%Tabla 5. Configuración de los nodos Cassandra

%Para terminar con la configuración de Cassandra, es conveniente entender los valores asignados a los atributos initial_token y seed_provider. 


Cassandra ofrece herramientas como nodetool para comprobar que este ha sido instalado de forma correcta a través del cluster.

// mencionar como comprobar mediante nodetool que todo ha ido bien


\subsection{Configuración de Apache Spark}

///Cambiar los hostname de las máquinas

Asignar nombre univoco a cada máquina es otro de los pasos que ha de realizarse. Ello se logra modificando el fichero /etc/hostname y cambiando el valor que tiene por defecto (ubuntu) por el nombre con el que se quiera bautizar.

La configuración de Apache Spark puede ser realizada tanto de forma manual como automática, pero por la sencillez y comodidad de ofrece esta vez se ha elegido configurarlo de la segunda manera.

Apache Spark ofrece una serie de scripts como start-all y stop-all que ejecutados en el nodo maestro permiten poner en marcha o parar Spark en todos los nodos del cluster.

Para que estos scripts funcionen de forma correcta será necesario hacer una pequeña configuración. Dentro de la carpeta conf de todos los nodos de la infraestructura se ha de crear un fichero llamado slaves, y dentro, especificar el hostname de las maquinas que vayan a trabajar como tal.

